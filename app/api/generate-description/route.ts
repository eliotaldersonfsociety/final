import { NextRequest, NextResponse } from "next/server";
import { GoogleGenerativeAI } from "@google/generative-ai";

const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const GROQ_API_KEY = process.env.GROQ_API_KEY;
const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;
const HF_API_KEY = process.env.HF_API_KEY;

if (!GEMINI_API_KEY || !GROQ_API_KEY || !OPENROUTER_API_KEY || !HF_API_KEY) {
  throw new Error("Faltan una o m√°s variables de entorno necesarias");
}

const systemInstruction = `Act√∫a como un vendedor persuasivo que cambia las palabras por sin√≥nimos cada vez que se env√≠e el texto.
Adem√°s, agrega emoticones en lugares naturales en el texto, como para expresar emociones o enfatizar ciertos puntos.
Utiliza una variedad de emoticones de manera aleatoria para cada mensaje.`;

/**
 * API Route en Next.js para generar descripciones de productos con fallback entre Gemini, Groq, OpenRouter y HuggingFace
 */
export async function POST(req: NextRequest) {
  try {
    const { title, category } = await req.json();

    if (!title || !category) {
      return NextResponse.json({ error: "T√≠tulo y categor√≠a son requeridos" }, { status: 400 });
    }

    console.log("üì© Recibido en API:", { title, category });

    const prompt = `Genera una descripci√≥n atractiva y en espa√±ol para un producto llamado "${title}" que pertenece a la categor√≠a "${category}". La descripci√≥n debe ser persuasiva y destacar sus caracter√≠sticas.`;

    const description = await fallbackGenerate(prompt, systemInstruction);

    return NextResponse.json({ description });
  } catch (error) {
    console.error("‚ùå Error interno del servidor:", error);
    return NextResponse.json({ error: "Error interno del servidor" }, { status: 500 });
  }
}

// üö® Manejador de fallback entre m√∫ltiples IAs
async function fallbackGenerate(prompt: string, systemInstruction: string): Promise<string> {
  const providers = [tryGemini, tryGroq, tryOpenRouter, tryHuggingFace];

  for (const providerFn of providers) {
    try {
      const result = await providerFn(prompt, systemInstruction);
      if (result) return result;
    } catch (err) {
      if (err instanceof Error) {
        console.warn(`‚ö†Ô∏è Fallback: fall√≥ ${providerFn.name}`, err.message);
      } else {
        console.warn(`‚ö†Ô∏è Fallback: fall√≥ ${providerFn.name}`, err);
      }
    }
  }

  throw new Error("Todas las IAs fallaron");
}

// üéØ GEMINI
async function tryGemini(prompt: string, systemInstruction: string): Promise<string> {
  const genAI = new GoogleGenerativeAI(GEMINI_API_KEY!);
  const model = genAI.getGenerativeModel({
    model: "gemini-1.5-flash",
    systemInstruction,
  });

  const chatSession = model.startChat({
    generationConfig: {
      temperature: 0.1,
      topP: 0.95,
      topK: 40,
      maxOutputTokens: 8192,
      responseMimeType: "text/plain",
    },
    history: [],
  });

  const result = await chatSession.sendMessage(prompt);
  console.log("‚úÖ Gemini respondi√≥");
  return result.response.text();
}

// üéØ GROQ
async function tryGroq(prompt: string): Promise<string> {
  const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${GROQ_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "llama3-8b-8192",
      messages: [
        { role: "system", content: systemInstruction },
        { role: "user", content: prompt },
      ],
      temperature: 0.6,
      max_tokens: 2048,
    }),
  });

  const data = await response.json();
  console.log("‚úÖ Groq respondi√≥");
  return data.choices?.[0]?.message?.content || "Respuesta vac√≠a de Groq";
}

// üéØ OpenRouter
async function tryOpenRouter(prompt: string): Promise<string> {
  const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${OPENROUTER_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "meta-llama/llama-3-8b-instruct:nitro",
      messages: [
        { role: "system", content: systemInstruction },
        { role: "user", content: prompt },
      ],
    }),
  });

  const data = await response.json();
  console.log("‚úÖ OpenRouter respondi√≥");
  return data.choices?.[0]?.message?.content || "Respuesta vac√≠a de OpenRouter";
}

// üéØ HuggingFace
async function tryHuggingFace(prompt: string): Promise<string> {
  const response = await fetch("https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${HF_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({ inputs: prompt }),
  });

  const data = await response.json();
  console.log("‚úÖ HuggingFace respondi√≥");

  if (typeof data === "string") return data;
  if (Array.isArray(data) && data[0]?.generated_text) return data[0].generated_text;
  throw new Error("Respuesta inv√°lida de HuggingFace");
}
